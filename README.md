# Causal Bayesian Networks for correction of potential bias in ML models

### Higher School of Economics
### Master of Data Science Final Project


## Abstract

It is now public knowledge that systems created for automated decision-making tend to absorb the bias of the underlying datasets used for training or from the practitioners creating these systems.

Identifying and correcting bias in machine learning is not always an easy task. The main purpose of this work is to 1) briefly describe the problem of fairness in ML models and the work that has been done in this area, 2) offer a deep explanation on how Causal Bayesian networks can be used to identify and correct unfair path-specific bias, and 3) present practical examples of this proposed solution in action.

We will start with a motivating example before going through the concepts of fairness in ML, causality and Bayesian Networks. By the end of this work we will have the necessary context to put these concepts into practice with concrete examples using synthetic data and a publicly available dataset.

A main guiding principle of this work is that a causal lens through the explicit definition of a causal graph to model the underlying data generating process is necessary in most cases to accurately measure and counteract bias in complex processes.

## Description

This notebook serves as a code companion to the final report. 

## Team members

- Kalle Bylin

## Reproducing Experiments

